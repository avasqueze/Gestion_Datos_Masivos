{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57071dd",
   "metadata": {},
   "source": [
    "# ¬øQU√â ES EL COSTO COMPUTACIONAL EN BIG DATA?\n",
    "\n",
    "En **entornos de Big Data**, el **costo computacional** hace referencia a la cantidad de **recursos de procesamiento, memoria, almacenamiento y red** necesarios para mover, transformar y analizar grandes vol√∫menes de informaci√≥n. Este costo no solo impacta el **tiempo de ejecuci√≥n**, sino tambi√©n la **escalabilidad**, la **latencia de las aplicaciones** y los **gastos en infraestructura**, especialmente cuando se trabaja en la nube.\n",
    "\n",
    "## Factores clave\n",
    "\n",
    "* **Volumen de datos:** mientras m√°s grande sea el dataset (terabytes o petabytes), mayor ser√° el costo en c√≥mputo y almacenamiento.\n",
    "* **Complejidad de los procesos:** transformaciones pesadas, uniones distribuidas o algoritmos de aprendizaje autom√°tico sobre millones de registros demandan muchos recursos.\n",
    "* **Arquitectura y paralelizaci√≥n:** la elecci√≥n entre procesamiento en **lotes (batch)** o **tiempo real (streaming)**, y el uso de cl√∫steres distribuidos (Spark, Flink, Hadoop) influyen en el costo.\n",
    "* **Optimizaci√≥n del pipeline:** √≠ndices, particiones, cach√©s y uso eficiente de memoria ayudan a reducir el consumo.\n",
    "\n",
    "En este cuaderno, exploraremos:\n",
    "\n",
    "- El concepto de eficiencia de algoritmos y la notaci√≥n Big O.\n",
    "- C√≥mo medir el tiempo de ejecuci√≥n en Python.\n",
    "- Casos de estudio comparando diferentes algoritmos.\n",
    "- Visualizaci√≥n del tiempo de ejecuci√≥n versus el tama√±o del problema.\n",
    "- Discusi√≥n sobre consideraciones de uso de memoria.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabb821",
   "metadata": {},
   "source": [
    "## Ejemplos\n",
    "\n",
    "### Clasificaci√≥n en cl√∫sters\n",
    "\n",
    "Al entrenar un modelo de **clasificaci√≥n en un cl√∫ster de Big Data**, como un **bosque aleatorio** o una **red neuronal profunda**, el costo computacional aumenta con:\n",
    "\n",
    "* El **tama√±o del conjunto de entrenamiento** (m√°s nodos deben procesar datos en paralelo).\n",
    "* La **complejidad del modelo** (m√°s √°rboles, capas o neuronas incrementan el tiempo y los recursos).\n",
    "* La necesidad de **reentrenar frecuentemente** para datos en streaming, lo que exige mayor disponibilidad y tolerancia a fallos.\n",
    "\n",
    "En este contexto, gestionar el costo computacional es clave para lograr **pipelines eficientes**, **sistemas escalables** y **anal√≠tica en tiempo razonable** sin sobrepasar los presupuestos de infraestructura.\n",
    "\n",
    "### B√∫squeda de patrones en Big Data\n",
    "\n",
    "La **b√∫squeda de patrones** es una tarea fundamental en procesos como el **an√°lisis de im√°genes, series temporales o textos masivos**.\n",
    "\n",
    "* **Enfoque de fuerza bruta:** recorrer todos los datos de forma secuencial para identificar patrones puede resultar extremadamente costoso en t√©rminos de **tiempo de procesamiento, uso de CPU/GPU y memoria**, sobre todo cuando los vol√∫menes de informaci√≥n alcanzan terabytes o petabytes.\n",
    "\n",
    "* **Enfoques avanzados:** t√©cnicas de **aprendizaje profundo (deep learning)** y **modelos distribuidos** permiten **paralelizar el an√°lisis** y **optimizar la b√∫squeda**. Esto reduce el costo computacional al aprovechar arquitecturas modernas como **GPUs, TPUs** y **cl√∫steres distribuidos** con frameworks (TensorFlow, PyTorch, Spark MLlib).\n",
    "\n",
    "En un pipeline de Big Data que procesa millones de im√°genes m√©dicas, un enfoque de fuerza bruta para detectar anomal√≠as ser√≠a inviable. En cambio, un modelo de redes neuronales convolucionales (CNN) desplegado en un cl√∫ster distribuido puede **detectar patrones relevantes de manera m√°s r√°pida, escalable y eficiente en costos**.\n",
    "\n",
    "## An√°lisis de grafos\n",
    "\n",
    "El **an√°lisis de grafos** es clave para problemas como el **estudio de redes sociales**, la **detecci√≥n de comunidades**, la **identificaci√≥n de influenciadores**, o el **an√°lisis de relaciones en bases de datos y sistemas de conocimiento**.\n",
    "\n",
    "* **Alta complejidad:** cuando la cantidad de **nodos** y **aristas** es muy grande (millones o incluso billones), el **costo computacional** crece de manera exponencial, ya que recorrer el grafo completo exige mucho tiempo y memoria.\n",
    "\n",
    "* **Algoritmos eficientes:** para manejar estas escalas se utilizan **algoritmos distribuidos y optimizados** que permiten realizar operaciones como **PageRank, detecci√≥n de cliques, caminos m√°s cortos o clustering de grafos** sobre plataformas de Big Data. Frameworks como **Apache Spark GraphX, Neo4j, GraphFrames o Pregel** permiten paralelizar estas tareas.\n",
    "\n",
    "En una red social global, al aplicar algoritmos distribuidos de grafos sobre un cl√∫ster, es posible **procesar billones de relaciones de manera escalable y en tiempos razonables**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a729fd",
   "metadata": {},
   "source": [
    "## ¬øPor qu√© es clave considerar el costo computacional en Big Data?\n",
    "\n",
    "### 1. **Toma de decisiones estrat√©gicas**\n",
    "\n",
    "En proyectos de **transformaci√≥n digital** y **anal√≠tica avanzada**, la direcci√≥n debe evaluar el **costo computacional** de cada tecnolog√≠a (IA, blockchain, big data, IoT) antes de adoptarla:\n",
    "\n",
    "* **Priorizaci√≥n de proyectos:** ¬øvale la pena entrenar un modelo de machine learning complejo que consume semanas de GPUs y millones de d√≥lares?\n",
    "* **Balance costo/beneficio:** en algunos casos, modelos **livianos (TinyML, MobileNet)** son m√°s sostenibles que arquitecturas pesadas.\n",
    "* **Infraestructura:** decidir entre **on-premise** (inversi√≥n inicial alta) o **cloud computing** (flexibilidad, pero costos variables seg√∫n uso).\n",
    "\n",
    "üí° *Ejemplo:* una empresa que implementa **vision por computador** para control de calidad en f√°bricas debe elegir entre:\n",
    "\n",
    "* Un algoritmo muy preciso pero caro en GPUs.\n",
    "* Un modelo m√°s eficiente (ej. **MobileNet en edge devices**) con menor costo.\n",
    "\n",
    "### 2. **Optimizaci√≥n de recursos**\n",
    "\n",
    "La ingenier√≠a de datos debe garantizar que el costo computacional no crezca sin control:\n",
    "\n",
    "* **Escalabilidad:** un pipeline mal optimizado puede generar costos exponenciales con el aumento de usuarios (ej. apps que sobrecargan RAM).\n",
    "* **Automatizaci√≥n:** **RPA (Robotic Process Automation)** y optimizaci√≥n de queries/ETL reducen costos frente a procesos manuales o ineficientes.\n",
    "* **Monitorizaci√≥n en la nube:** servicios como **AWS Cost Explorer** o **Google Cloud Billing** permiten auditar en tiempo real.\n",
    "\n",
    "üí° *Ejemplo:* **Netflix** reduce el costo de transmisi√≥n masiva aplicando c√≥decs de compresi√≥n m√°s eficientes (**AV1**), que disminuyen el ancho de banda sin perder calidad.\n",
    "\n",
    "### 3. **Sostenibilidad y ESG**\n",
    "\n",
    "El costo computacional no solo es econ√≥mico: tambi√©n afecta la **huella de carbono**.\n",
    "\n",
    "* **Centros de datos verdes:** elegir proveedores que usan energ√≠as renovables (Google Cloud, AWS con energ√≠a solar/e√≥lica).\n",
    "* **Green IT en IA:** aplicar t√©cnicas de **pruning** y **quantization** para reducir consumo energ√©tico.\n",
    "* **KPIs ambientales:** medir indicadores como **PUE (Power Usage Effectiveness)** en data centers.\n",
    "\n",
    "üìä *Dato:* Entrenar **GPT-3** gener√≥ unas **552 toneladas de CO‚ÇÇ**. Estrategias como **federated learning** reducen el costo energ√©tico al procesar datos localmente.\n",
    "\n",
    "### 4. **Innovaci√≥n con restricciones**\n",
    "\n",
    "No todas las empresas tienen el presupuesto de Google o Amazon. Las soluciones deben ser **eficientes y frugales**:\n",
    "\n",
    "* **Serverless computing (AWS Lambda, GCP Functions):** pagar solo por uso.\n",
    "* **Arquitecturas edge computing:** menor costo de transmisi√≥n y latencia frente a cloud centralizado.\n",
    "* **Hardware adecuado:** balancear inversi√≥n en **GPUs para IA** vs. **CPUs optimizadas** para procesamiento masivo de datos.\n",
    "\n",
    "üí° *Caso real:* startups de salud usan modelos como **EfficientNet** para diagn√≥stico de im√°genes m√©dicas con bajo costo computacional, evitando infraestructura cara.\n",
    "\n",
    "### 5. **Riesgos y gobernanza**\n",
    "\n",
    "El costo computacional tambi√©n implica riesgos financieros y regulatorios:\n",
    "\n",
    "* **Ciberseguridad:** ataques DDoS pueden disparar costos de infraestructura por sobrecarga en servidores.\n",
    "* **Cumplimiento normativo (GDPR, LGPD):** procesamiento local obligatorio incrementa costos frente a soluciones distribuidas en la nube.\n",
    "* **Baja latencia vs. encriptaci√≥n:** procesar en tiempo real exige infraestructura costosa; a√±adir seguridad (encriptaci√≥n) eleva a√∫n m√°s la carga computacional.\n",
    "\n",
    "üí° *Ejemplo:* un **banco** que procesa millones de transacciones por segundo debe balancear:\n",
    "\n",
    "* **Velocidad** con infraestructura de baja latencia (costo alto).\n",
    "* **Cumplimiento y seguridad**, que agregan cargas de c√≥mputo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f7d25",
   "metadata": {},
   "source": [
    "## ¬øC√ìMO SE CALCULA EL COSTO COMPUTACIONAL EN BIG DATA?\n",
    "\n",
    "El **costo computacional** en proyectos de **ingenier√≠a de datos y anal√≠tica en gran escala** puede evaluarse desde diferentes √°ngulos. No existe una √∫nica m√©trica universal: depende del tipo de tarea, del volumen de datos y de la infraestructura. A continuaci√≥n, algunos de los enfoques m√°s utilizados:\n",
    "\n",
    "### 1. **Tiempo de ejecuci√≥n (performance real)**\n",
    "\n",
    "* Se mide cu√°nto tarda un pipeline, query o modelo en procesar un volumen de datos.\n",
    "* Ejemplo: un job de **Spark** que procesa 1 TB en 3 minutos frente a otro que tarda 15 minutos. El primero es m√°s eficiente en costo temporal y probablemente en uso de recursos.\n",
    "* En ambientes cloud, el **tiempo de ejecuci√≥n** est√° directamente ligado al **costo monetario**, ya que m√°s tiempo significa m√°s horas de c√≥mputo facturadas.\n",
    "\n",
    "### 2. **Complejidad computacional (an√°lisis te√≥rico)**\n",
    "\n",
    "* Se mide con **notaci√≥n Big-O**: O(n), O(n log n), O(n¬≤), etc.\n",
    "* En Big Data, algoritmos con **O(n¬≤)** se vuelven inviables al crecer los datos (millones de registros).\n",
    "* Ejemplo: un algoritmo de b√∫squeda secuencial O(n) sobre un grafo con mil millones de nodos puede ser reemplazado por un enfoque distribuido m√°s eficiente (ej. PageRank optimizado en GraphX).\n",
    "\n",
    "### 3. **Uso de recursos (medici√≥n pr√°ctica)**\n",
    "\n",
    "* Incluye **CPU, GPU, memoria RAM, disco, ancho de banda de red** y **costos de almacenamiento**.\n",
    "* Ejemplo: un proceso de ETL que carga un dataset completo en memoria puede ser mucho m√°s costoso que uno que procesa en *streaming* por lotes peque√±os.\n",
    "* Herramientas como **Spark UI, Kubernetes Metrics, AWS CloudWatch o GCP Stackdriver** permiten medir este consumo.\n",
    "\n",
    "### 4. **Escalabilidad (capacidad de crecer con los datos)**\n",
    "\n",
    "* Eval√∫a si el sistema mantiene eficiencia al aumentar volumen o usuarios.\n",
    "* Ejemplo: un pipeline en **batch** que funciona con 10 GB pero falla con 10 TB no es escalable.\n",
    "* La escalabilidad puede lograrse con **arquitecturas distribuidas** (Hadoop, Spark, Flink, Dask) que permiten dividir la carga entre m√∫ltiples nodos.\n",
    "\n",
    "\n",
    "‚úÖ En **ingenier√≠a de datos y Big Data**, calcular el costo computacional implica combinar estas perspectivas:\n",
    "\n",
    "* **Te√≥rica (complejidad)** ‚Üí para estimar crecimiento.\n",
    "* **Pr√°ctica (tiempo y recursos)** ‚Üí para medir en producci√≥n.\n",
    "* **Estrat√©gica (escalabilidad y costo econ√≥mico/energ√©tico)** ‚Üí para planificar a largo plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac9859",
   "metadata": {},
   "source": [
    "## Complejidad Temporal y Notaci√≥n Big O\n",
    "\n",
    "La **complejidad temporal** de un algoritmo es una medida te√≥rica que describe la cantidad de tiempo que un algoritmo tarda en ejecutarse en funci√≥n del tama√±o de la entrada. Es una herramienta fundamental en inform√°tica y matem√°ticas para analizar y comparar la eficiencia de diferentes algoritmos.\n",
    "\n",
    "La **notaci√≥n Big O** es una notaci√≥n matem√°tica utilizada para describir el comportamiento asint√≥tico de funciones. En el contexto de algoritmos, se utiliza para clasificar el tiempo de ejecuci√≥n o uso de recursos en funci√≥n del tama√±o de la entrada.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65238311",
   "metadata": {},
   "source": [
    "### **Conceptos Clave**\n",
    "\n",
    "#### **Comportamiento Asint√≥tico**\n",
    "\n",
    "El comportamiento asint√≥tico se refiere al an√°lisis del rendimiento de un algoritmo cuando el tama√±o de la entrada tiende a infinito. Nos permite enfocarnos en la tendencia general y no en detalles espec√≠ficos para entradas peque√±as.\n",
    "\n",
    "#### **Funciones de Complejidad Comunes**\n",
    "\n",
    "- **O(1) - Tiempo Constante**: El tiempo de ejecuci√≥n no depende del tama√±o de la entrada.\n",
    "- **O(log n) - Tiempo Logar√≠tmico**: El tiempo de ejecuci√≥n crece proporcionalmente al logaritmo del tama√±o de la entrada.\n",
    "- **O(n) - Tiempo Lineal**: El tiempo de ejecuci√≥n crece linealmente con el tama√±o de la entrada.\n",
    "- **O(n log n) - Tiempo Lineal-Logar√≠tmico**: Combinaci√≥n de lineal y logar√≠tmico, com√∫n en algoritmos de ordenamiento eficientes.\n",
    "- **O(n¬≤) - Tiempo Cuadr√°tico**: El tiempo de ejecuci√≥n es proporcional al cuadrado del tama√±o de la entrada, t√≠pico en algoritmos con bucles anidados.\n",
    "- **O(2‚Åø) - Tiempo Exponencial**: El tiempo de ejecuci√≥n se duplica con cada incremento en el tama√±o de la entrada; ineficiente para grandes n.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603350e5",
   "metadata": {},
   "source": [
    "### **Notaci√≥n Big O**\n",
    "\n",
    "La notaci√≥n Big O formaliza el l√≠mite superior del crecimiento de una funci√≥n. Decimos que una funci√≥n f(n) es O(g(n)) si existen constantes positivas **c** y **n‚ÇÄ** tales que:\n",
    "\n",
    "$$\n",
    "0 \\leq f(n) \\leq c \\cdot g(n) \\quad \\text{para todo} \\ n \\geq n‚ÇÄ\n",
    "$$\n",
    "\n",
    "Esto implica que, para valores suficientemente grandes de n, f(n) no crece m√°s r√°pido que g(n), excepto por un factor constante.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba524dfd",
   "metadata": {},
   "source": [
    "### **Casos Detallados**\n",
    "\n",
    "#### **Tiempo Constante - O(1)**\n",
    "\n",
    "El tiempo de ejecuci√≥n es independiente del tama√±o de la entrada.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Acceder a un elemento espec√≠fico en un array.\n",
    "\n",
    "```python\n",
    "def obtener_elemento(array, √≠ndice):\n",
    "    return array[√≠ndice]\n",
    "```\n",
    "\n",
    "**An√°lisis:**\n",
    "\n",
    "La operaci√≥n de acceso directo en un array es constante, sin importar cu√°ntos elementos tenga el array.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c75e3",
   "metadata": {},
   "source": [
    "#### **Tiempo Logar√≠tmico - O(log n)**\n",
    "\n",
    "El tiempo de ejecuci√≥n aumenta logar√≠tmicamente con el tama√±o de la entrada. Cada paso reduce la cantidad de datos a la mitad.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "B√∫squeda binaria en un array ordenado.\n",
    "\n",
    "```python\n",
    "def b√∫squeda_binaria(array, objetivo):\n",
    "    izquierda = 0\n",
    "    derecha = len(array) - 1\n",
    "    while izquierda <= derecha:\n",
    "        medio = (izquierda + derecha) // 2\n",
    "        if array[medio] == objetivo:\n",
    "            return medio\n",
    "        elif array[medio] < objetivo:\n",
    "            izquierda = medio + 1\n",
    "        else:\n",
    "            derecha = medio - 1\n",
    "    return -1\n",
    "```\n",
    "\n",
    "**An√°lisis:**\n",
    "\n",
    "En cada iteraci√≥n, el espacio de b√∫squeda se reduce a la mitad, resultando en un m√°ximo de log‚ÇÇ(n) iteraciones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23394d1d",
   "metadata": {},
   "source": [
    "#### **Tiempo Lineal - O(n)**\n",
    "\n",
    "El tiempo de ejecuci√≥n es directamente proporcional al tama√±o de la entrada.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Encontrar el elemento m√°ximo en una .\n",
    "\n",
    "```python\n",
    "def encontrar_m√°ximo(lista):\n",
    "    m√°ximo = lista[0]\n",
    "    for elemento en lista:\n",
    "        if elemento > m√°ximo:\n",
    "            m√°ximo = elemento\n",
    "    return m√°ximo\n",
    "```\n",
    "\n",
    "**An√°lisis:**\n",
    "\n",
    "Se recorre cada elemento una vez, realizando una comparaci√≥n por elemento.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63217f46",
   "metadata": {},
   "source": [
    "#### **Tiempo Lineal-Logar√≠tmico - O(n log n)**\n",
    "\n",
    "Combinaci√≥n de comportamiento lineal y logar√≠tmico. Com√∫n en algoritmos de ordenamiento eficientes.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Ordenamiento por mezcla (Merge Sort).\n",
    "\n",
    "<p align=\"center\">\n",
    "<image src=\"amerge-sort-algorithm.png.webp\" alt=\"Descripci√≥n de la imagen\">\n",
    "</p>\n",
    "\n",
    "```python\n",
    "def merge_sort(lista):\n",
    "    if len(lista) > 1:\n",
    "        medio = len(lista) // 2\n",
    "        izquierda = lista[:medio]\n",
    "        derecha = lista[medio:]\n",
    "        merge_sort(izquierda)\n",
    "        merge_sort(derecha)\n",
    "        i = j = k = 0\n",
    "        while i < len(izquierda) and j < len(derecha):\n",
    "            if izquierda[i] < derecha[j]:\n",
    "                lista[k] = izquierda[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                lista[k] = derecha[j]\n",
    "                j += 1\n",
    "            k += 1\n",
    "            while i < len(izquierda):\n",
    "                lista[k] = izquierda[i]\n",
    "                i += 1\n",
    "                k += 1\n",
    "            while j < len(derecha):\n",
    "                lista[k] = derecha[j]\n",
    "                j += 1\n",
    "                k += 1\n",
    "```\n",
    "\n",
    "**An√°lisis:**\n",
    "\n",
    "Divide la lista repetidamente (log n) y combina las sublistas (n), resultando en O(n log n).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7372d",
   "metadata": {},
   "source": [
    "#### **Tiempo Cuadr√°tico - O(n¬≤)**\n",
    "\n",
    "El tiempo de ejecuci√≥n es proporcional al cuadrado del tama√±o de la entrada.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Ordenamiento por burbuja.\n",
    "\n",
    "```python\n",
    "\n",
    "def ordenamiento_burbuja(lista):\n",
    "    n = len(lista)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if lista[j] > lista[j + 1]:\n",
    "                lista[j], lista[j + 1] = lista[j + 1], lista[j]\n",
    "```\n",
    "\n",
    "**An√°lisis:**\n",
    "\n",
    "Dos bucles anidados que recorren la lista, resultando en n * n = n¬≤ iteraciones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34970bc",
   "metadata": {},
   "source": [
    "#### **Tiempo Exponencial - O(2‚Åø)**\n",
    "\n",
    "El tiempo de ejecuci√≥n se duplica con cada incremento en el tama√±o de la entrada.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Resoluci√≥n de problemas combinatorios, como el c√°lculo de todos los subconjuntos de un conjunto.\n",
    "\n",
    "```python\n",
    "def generar_subconjuntos(conjunto):\n",
    "    if not conjunto:\n",
    "        return [[]]\n",
    "    elemento = conjunto[0]\n",
    "    sin_elemento = generar_subconjuntos(conjunto[1:])\n",
    "    con_elemento = [ [elemento] + subconjunto for subconjunto in sin_elemento ]\n",
    "    return sin_elemento + con_elemento\n",
    "```\n",
    "\n",
    "**An√°lisis:**\n",
    "\n",
    "El n√∫mero de subconjuntos de un conjunto de tama√±o n es 2‚Åø.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e9e8e",
   "metadata": {},
   "source": [
    "### **Reglas para Calcular la Complejidad**\n",
    "\n",
    "- **Regla de la Suma:** Si un algoritmo realiza una secuencia de pasos, la complejidad total es la suma de las complejidades de cada paso.\n",
    "\n",
    "  $$\n",
    "  O(f(n)) + O(g(n)) = O(\\max(f(n), g(n)))\n",
    "  $$\n",
    "\n",
    "- **Regla del Producto:** Para bucles anidados, la complejidad es el producto de las complejidades de cada bucle.\n",
    "\n",
    "  $$\n",
    "  O(n) \\times O(n) = O(n^2)\n",
    "  $$\n",
    "\n",
    "#### **Ignorar Constantes y T√©rminos de Menor Orden**\n",
    "\n",
    "En notaci√≥n Big O, se omiten constantes multiplicativas y t√©rminos de menor grado porque el comportamiento asint√≥tico se centra en el crecimiento dominante.\n",
    "\n",
    "- O(3n) se simplifica a O(n)\n",
    "- O(n + log n) se simplifica a O(n)\n",
    "- O(n¬≤ + n) se simplifica a O(n¬≤)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5dfe01",
   "metadata": {},
   "source": [
    "### Importancia\n",
    "\n",
    "La complejidad temporal es crucial debido a:\n",
    "\n",
    "- **Escalabilidad:** Al trabajar con grandes conjuntos de datos o matrices, un aumento en la complejidad puede hacer que un algoritmo sea impracticable.\n",
    "- **Optimizaci√≥n:** Permite identificar partes del algoritmo que pueden mejorarse.\n",
    "- **Comparaci√≥n de Algoritmos:** Facilita la elecci√≥n del algoritmo m√°s eficiente para un problema dado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4998d",
   "metadata": {},
   "source": [
    "### **C√≥mo Realizar el An√°lisis de Complejidad**\n",
    "\n",
    "1. **Identificar las Operaciones B√°sicas:**\n",
    "   - Las que m√°s contribuyen al tiempo total.\n",
    "2. **Contar el N√∫mero de Veces que se Ejecutan:**\n",
    "   - En funci√≥n del tama√±o de la entrada n.\n",
    "3. **Expresar el Tiempo Total:**\n",
    "   - Como una funci√≥n matem√°tica de n.\n",
    "4. **Simplificar Usando Notaci√≥n Big O:**\n",
    "   - Mantener solo el t√©rmino de mayor grado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a9be7",
   "metadata": {},
   "source": [
    "### **Limitaciones de la Notaci√≥n Big O**\n",
    "\n",
    "- **No Indica el Tiempo Exacto de Ejecuci√≥n:** Solo proporciona una cota superior.\n",
    "- **No Considera Constantes Ocultas:** Las constantes pueden ser significativas en la pr√°ctica.\n",
    "- **Asume que Todas las Operaciones Toman el Mismo Tiempo:** Lo cual puede no ser cierto en sistemas reales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measuring-time",
   "metadata": {},
   "source": [
    "## Como Medir el Tiempo de Ejecuci√≥n en Python\n",
    "\n",
    "Python proporciona los m√≥dulos `time` y `timeit` para medir el tiempo de ejecuci√≥n de fragmentos de c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfaecae",
   "metadata": {},
   "source": [
    "### Ejemplo 1: \n",
    "Calcular el promedio de un conjunto de 10 millones de n√∫meros aleatorios utilizando un enfoque de fuerza bruta (sumando todos los valores y dividiendo entre el n√∫mero de elementos). Medir el tiempo de ejecuci√≥n del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c967202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Generar 10 millones de n√∫meros aleatorios\n",
    "data = [random.random() for _ in range(1000000000)]\n",
    "\n",
    "# Calcular el promedio utilizando un enfoque de fuerza bruta\n",
    "start_time = time.time()\n",
    "total = sum(data)\n",
    "average = total / len(data)\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de ejecuci√≥n del algoritmo\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"El promedio es: {average}\")\n",
    "print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224dd4b",
   "metadata": {},
   "source": [
    "## Ejercicio 2: \n",
    "\n",
    "Ordenar un conjunto de 100.000 n√∫meros aleatorios utilizando el algoritmo de ordenamiento de selecci√≥n. Medir el tiempo de ejecuci√≥n del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62a113a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Ordenar el conjunto de datos utilizando el algoritmo de selecci√≥n\u001b[39;00m\n\u001b[1;32m     18\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mselection_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Medir el tiempo de ejecuci√≥n del algoritmo\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mselection_sort\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m min_idx \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, n):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data[j] \u001b[38;5;241m<\u001b[39m data[min_idx]:\n\u001b[1;32m     14\u001b[0m         min_idx \u001b[38;5;241m=\u001b[39m j\n\u001b[1;32m     15\u001b[0m data[i], data[min_idx] \u001b[38;5;241m=\u001b[39m data[min_idx], data[i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Generar 100,000 n√∫meros aleatorios\n",
    "data = [random.randint(1, 100000) for _ in range(100000)]\n",
    "\n",
    "# Implementar el algoritmo de ordenamiento de selecci√≥n\n",
    "def selection_sort(data):\n",
    "    n = len(data)\n",
    "    for i in range(n):\n",
    "        min_idx = i\n",
    "        for j in range(i+1, n):\n",
    "            if data[j] < data[min_idx]:\n",
    "                min_idx = j\n",
    "        data[i], data[min_idx] = data[min_idx], data[i]\n",
    "\n",
    "# Ordenar el conjunto de datos utilizando el algoritmo de selecci√≥n\n",
    "start_time = time.time()\n",
    "selection_sort(data)\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de ejecuci√≥n del algoritmo\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"El conjunto de datos ordenado es: {data}\")\n",
    "print(f\"Tiempo de ejecuci√≥n: {execution_time} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f98a58",
   "metadata": {},
   "source": [
    "### Ejemplo 3: \n",
    "Medir el tiempo de ejecucion de un bucle simple usando `timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simple-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo promedio de ejecuci√≥n en 10 ejecuciones: 0.000459 segundos\n",
      "Tiempo promedio de ejecuci√≥n en 10 ejecuciones: 0.003394 segundos\n",
      "Tiempo promedio de ejecuci√≥n en 10 ejecuciones: 0.036714 segundos\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# Definir una funci√≥n simple\n",
    "def bucle_simple(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "# Medir el tiempo de ejecuci√≥n\n",
    "n = 10000\n",
    "tiempo_ejecucion = timeit.timeit(lambda: bucle_simple(n), number=10)\n",
    "print(f\"Tiempo promedio de ejecuci√≥n en 10 ejecuciones: {tiempo_ejecucion / 10:.6f} segundos\")\n",
    "\n",
    "n = 100000\n",
    "tiempo_ejecucion = timeit.timeit(lambda: bucle_simple(n), number=10)\n",
    "print(f\"Tiempo promedio de ejecuci√≥n en 10 ejecuciones: {tiempo_ejecucion / 10:.6f} segundos\")\n",
    "\n",
    "n = 1000000\n",
    "tiempo_ejecucion = timeit.timeit(lambda: bucle_simple(n), number=10)\n",
    "print(f\"Tiempo promedio de ejecuci√≥n en 10 ejecuciones: {tiempo_ejecucion / 10:.6f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1111b91",
   "metadata": {},
   "source": [
    "## Analisis de Complejidad Computacional:\n",
    "\n",
    "\n",
    "Ejemplo 1:  Analizar la complejidad computacional de un algoritmo para calcular el m√°ximo de un conjunto de 10000 n√∫meros aleatorios utilizando un enfoque de fuerza bruta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac68d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generar 100 n√∫meros aleatorios\n",
    "data = [random.randint(1, 10000) for _ in range(1000)]\n",
    "\n",
    "# Calcular el m√°ximo utilizando un enfoque de fuerza bruta\n",
    "max_num = data[0]\n",
    "for num in data:\n",
    "    if num > max_num:\n",
    "        max_num = num\n",
    "print(num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd364db",
   "metadata": {},
   "source": [
    "En este caso la complejidad computacional es O(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb1c8f",
   "metadata": {},
   "source": [
    "Ejemplo 2: \n",
    "\n",
    "Contar el n√∫mero de elementos duplicados en un conjunto de 1000 n√∫meros aleatorios. Analizar la complejidad computacional del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generar 1000 n√∫meros aleatorios\n",
    "data = [random.randint(1, 1000) for _ in range(1000)]\n",
    "\n",
    "# Contar el n√∫mero de elementos duplicados utilizando un enfoque de fuerza bruta\n",
    "duplicates = set()\n",
    "for i in range(len(data)):\n",
    "    for j in range(i+1, len(data)):\n",
    "        if data[i] == data[j]:\n",
    "            duplicates.add(data[i])\n",
    "\n",
    "# Contar el n√∫mero de elementos duplicados\n",
    "num_duplicates = len(duplicates)\n",
    "print(num_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d6d37e",
   "metadata": {},
   "source": [
    "En este caso la complejidad computacional es O(n^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20e158",
   "metadata": {},
   "source": [
    "## Como Medir el Uso de Recursos:\n",
    "\n",
    "\n",
    "### Ejemplo 1:\n",
    "Ordenar un conjunto de 10.000 n√∫meros aleatorios en orden ascendente utilizando el algoritmo de ordenamiento por selecci√≥n. Medir el tiempo de ejecuci√≥n y la memoria utilizada por el algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ca612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Generar 10,000 n√∫meros aleatorios\n",
    "data = [random.randint(1, 10000) for _ in range(10000)]\n",
    "\n",
    "# Implementar el algoritmo de ordenamiento por selecci√≥n\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(data)):\n",
    "    min_index = i\n",
    "    for j in range(i+1, len(data)):\n",
    "        if data[j] < data[min_index]:\n",
    "            min_index = j\n",
    "    data[i], data[min_index] = data[min_index], data[i]\n",
    "\n",
    "end_time = time.time()\n",
    "# Medir el tiempo de ejecuci√≥n y la memoria utilizada\n",
    "time_elapsed = end_time - start_time\n",
    "memory_used = sys.getsizeof(data)\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {time_elapsed} segundos\")\n",
    "print(f\"Memoria utilizada: {memory_used} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba300796",
   "metadata": {},
   "source": [
    "### Ejemplo 2: \n",
    "\n",
    "Calcular la suma de dos matrices de 100x100. Medir el tiempo de ejecuci√≥n y la memoria utilizada por el algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Generar dos matrices de 100x100 con n√∫meros aleatorios\n",
    "matrix1 = [[random.randint(1, 100) for _ in range(100)] for _ in range(100)]\n",
    "matrix2 = [[random.randint(1, 100) for _ in range(100)] for _ in range(100)]\n",
    "\n",
    "# Implementar el algoritmo para sumar dos matrices\n",
    "start_time = time.time()\n",
    "\n",
    "result = [[0 for _ in range(100)] for _ in range(100)]\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        result[i][j] = matrix1[i][j] + matrix2[i][j]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de ejecuci√≥n y la memoria utilizada\n",
    "time_elapsed = end_time - start_time\n",
    "memory_used = sys.getsizeof(result)\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {time_elapsed} segundos\")\n",
    "print(f\"Memoria utilizada: {memory_used} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "case-study",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Caso de Estudio: Resolviendo Sistemas Lineales\n",
    "\n",
    "Consideremos resolver el sistema lineal **Ax = b**, donde **A** es una matriz **n x n**, y **b** es un vector de tama√±o **n**.\n",
    "\n",
    "### 3.2 M√©todos:\n",
    "\n",
    "- **Eliminaci√≥n Gaussiana**: M√©todo directo con complejidad temporal **O(n¬≥)**.\n",
    "- **Descomposici√≥n LU**: Factoriza la matriz **A** en matrices **L** y **U**.\n",
    "- **M√©todos Iterativos**: Como los m√©todos de Jacobi o Gauss-Seidel, √∫tiles para matrices grandes y dispersas.\n",
    "\n",
    "### Implementaci√≥n y Comparaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "implement-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu_solve, lu_factor\n",
    "from scipy.sparse import diags\n",
    "from scipy.sparse.linalg import cg  # M√©todo del Gradiente Conjugado\n",
    "import time\n",
    "\n",
    "# Funci√≥n para resolver usando Eliminaci√≥n Gaussiana (np.linalg.solve)\n",
    "def resolver_gaussiana(A, b):\n",
    "    return np.linalg.solve(A, b)\n",
    "\n",
    "# Funci√≥n para resolver usando Descomposici√≥n LU\n",
    "def resolver_lu(A, b):\n",
    "    lu, piv = lu_factor(A)\n",
    "    return lu_solve((lu, piv), b)\n",
    "\n",
    "# Funci√≥n para resolver usando M√©todo Iterativo (Gradiente Conjugado)\n",
    "def resolver_iterativo(A, b):\n",
    "    x, info = cg(A, b)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plotting",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.2 Grafica del Tiempo de Ejecuci√≥n vs. Tama√±o del Problema\n",
    "\n",
    "Vamos a medir y graficar el tiempo de ejecuci√≥n de estos m√©todos para diferentes tama√±os de **n**.\n",
    "\n",
    "### C√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-code",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tama√±os del problema\n",
    "valores_n = [100, 200, 400, 800, 1600, 3200, 6400]\n",
    "\n",
    "tiempos_gaussiana = []\n",
    "tiempos_lu = []\n",
    "tiempos_iterativo = []\n",
    "\n",
    "for n in valores_n:\n",
    "    # Crear una matriz y vector aleatorios\n",
    "    A = np.random.rand(n, n)\n",
    "    b = np.random.rand(n)\n",
    "\n",
    "    # Medir tiempo de Eliminaci√≥n Gaussiana\n",
    "    inicio = time.time()\n",
    "    resolver_gaussiana(A, b)\n",
    "    tiempos_gaussiana.append(time.time() - inicio)\n",
    "\n",
    "    # Medir tiempo de Descomposici√≥n LU\n",
    "    inicio = time.time()\n",
    "    resolver_lu(A, b)\n",
    "    tiempos_lu.append(time.time() - inicio)\n",
    "\n",
    "    # Medir tiempo del M√©todo Iterativo (usando una matriz dispersa diagonal para eficiencia)\n",
    "    diagonales = [np.ones(n-1), np.ones(n), np.ones(n-1)]\n",
    "    A_dispersa = diags(diagonales, offsets=[-1, 0, 1])\n",
    "    b_dispersa = np.ones(n)\n",
    "\n",
    "    inicio = time.time()\n",
    "    resolver_iterativo(A_dispersa, b_dispersa)\n",
    "    tiempos_iterativo.append(time.time() - inicio)\n",
    "\n",
    "# Graficando\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(valores_n, tiempos_gaussiana, 'o-', label='Eliminaci√≥n Gaussiana')\n",
    "plt.plot(valores_n, tiempos_lu, 's-', label='Descomposici√≥n LU')\n",
    "plt.plot(valores_n, tiempos_iterativo, '^-', label='M√©todo Iterativo')\n",
    "plt.xlabel('Tama√±o de la Matriz (n)')\n",
    "plt.ylabel('Tiempo de Ejecuci√≥n (segundos)')\n",
    "plt.title('Tiempo de Ejecuci√≥n vs. Tama√±o del Problema')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpretation",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n:\n",
    "\n",
    "- La **Eliminaci√≥n Gaussiana** y la **Descomposici√≥n LU** tienen tiempos de ejecuci√≥n que aumentan r√°pidamente con **n**.\n",
    "- Los **M√©todos Iterativos** escalan mejor para grandes valores de **n**, especialmente al tratar con matrices dispersas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8901d",
   "metadata": {},
   "source": [
    "## ANEXO\n",
    "\n",
    "### Algoritmo de Kahan\n",
    "\n",
    "El **algoritmo de Kahan**, tambi√©n conocido como *suma compensada de Kahan*, es un m√©todo num√©rico dise√±ado para **reducir los errores de redondeo** al sumar una secuencia de n√∫meros en coma flotante. Fue propuesto por **William Kahan en 1965** y se utiliza ampliamente en **computaci√≥n cient√≠fica, estad√≠stica y procesamiento num√©rico**.\n",
    "\n",
    "#### Idea principal\n",
    "\n",
    "Cuando se suman n√∫meros muy grandes con n√∫meros muy peque√±os, los decimales de menor magnitud tienden a perderse debido a los l√≠mites de precisi√≥n de los n√∫meros de punto flotante. El algoritmo de Kahan introduce una **variable de compensaci√≥n** que rastrea y corrige estos errores acumulados.\n",
    "\n",
    "#### Pasos b√°sicos\n",
    "\n",
    "1. Inicializar una suma (`s`) y una correcci√≥n (`c`) en cero.\n",
    "2. Para cada n√∫mero de la secuencia:\n",
    "\n",
    "   * Ajustar el n√∫mero a sumar restando la correcci√≥n acumulada.\n",
    "   * Agregarlo a la suma.\n",
    "   * Actualizar la correcci√≥n con el error de redondeo detectado.\n",
    "\n",
    "De esta manera, se evita que los errores de redondeo se propaguen a lo largo de la suma.\n",
    "\n",
    "### Implementaci√≥n en Python\n",
    "\n",
    "```python\n",
    "def kahan_sum(numbers):\n",
    "    \"\"\"\n",
    "    Implementaci√≥n del algoritmo de suma de Kahan.\n",
    "    \n",
    "    Args:\n",
    "        numbers (list[float]): Secuencia de n√∫meros en coma flotante a sumar.\n",
    "    \n",
    "    Returns:\n",
    "        float: Suma precisa con correcci√≥n de errores de redondeo.\n",
    "    \"\"\"\n",
    "    s = 0.0   # Suma acumulada\n",
    "    c = 0.0   # Correcci√≥n acumulada\n",
    "\n",
    "    for x in numbers:\n",
    "        y = x - c          # Ajuste con correcci√≥n previa\n",
    "        t = s + y          # Nueva suma\n",
    "        c = (t - s) - y    # Nuevo error de redondeo\n",
    "        s = t              # Actualizar suma\n",
    "    \n",
    "    return s\n",
    "```\n",
    "\n",
    "El algoritmo de Kahan es especialmente √∫til al **sumar grandes vol√∫menes de datos con magnitudes muy diferentes** (por ejemplo, `1e10 + 1e-5 + 1e-10`), donde la suma convencional perder√≠a precisi√≥n significativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541cddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kahan_sum(numbers):\n",
    "    \"\"\"\n",
    "    Implementaci√≥n del algoritmo de suma de Kahan.\n",
    "    \"\"\"\n",
    "    s = 0.0   # Suma acumulada\n",
    "    c = 0.0   # Correcci√≥n acumulada\n",
    "\n",
    "    for x in numbers:\n",
    "        y = x - c          # Ajustar con correcci√≥n previa\n",
    "        t = s + y          # Nueva suma\n",
    "        c = (t - s) - y    # Nuevo error de redondeo\n",
    "        s = t              # Actualizar suma\n",
    "    \n",
    "    return s\n",
    "\n",
    "\n",
    "# Ejemplo: n√∫meros muy grandes con n√∫meros muy peque√±os\n",
    "data = [1e10, 1.0, 1e-10, -1e10]\n",
    "\n",
    "# Suma normal en Python\n",
    "normal_sum = sum(data)\n",
    "\n",
    "# Suma con algoritmo de Kahan\n",
    "kahan_result = kahan_sum(data)\n",
    "\n",
    "print(\"Suma normal   :\", normal_sum)\n",
    "print(\"Suma de Kahan :\", kahan_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b70432",
   "metadata": {},
   "source": [
    "El arreglo data contiene un n√∫mero muy grande (1e10), un n√∫mero peque√±o (1.0), un n√∫mero diminuto (1e-10) y finalmente -1e10. La suma exacta deber√≠a ser aproximadamente \n",
    "\n",
    "1.0 + 1e-10 = 1.0000000001.\n",
    "\n",
    "Con la suma est√°ndar (sum()), Python pierde precisi√≥n debido al redondeo. Con la suma de Kahan, se conserva la correcci√≥n y el resultado es m√°s preciso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
